{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "We load all preprocessed subreddit submission files (parquet parts) produced from the original `.zst` dumps.  \n",
    "This step concatenates all parts into a single DataFrame to facilitate uniform cleaning and filtering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found parquet parts: 77 files\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>permalink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6qxh3</td>\n",
       "      <td>StockMarket</td>\n",
       "      <td>1215605912</td>\n",
       "      <td>Forex Trading Styles: Fundamental analysis - T...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>marketstock</td>\n",
       "      <td>http://www.marketstock.net/2008/07/forex-tradi...</td>\n",
       "      <td>/r/StockMarket/comments/6qxh3/forex_trading_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6qxh8</td>\n",
       "      <td>StockMarket</td>\n",
       "      <td>1215605967</td>\n",
       "      <td>How to invest your first 100$ in the stock market</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>marketstock</td>\n",
       "      <td>http://www.marketstock.net/2008/06/how-to-inve...</td>\n",
       "      <td>/r/StockMarket/comments/6qxh8/how_to_invest_yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7tpzv</td>\n",
       "      <td>StockMarket</td>\n",
       "      <td>1233351595</td>\n",
       "      <td>How to create and test a trading strategy, Par...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>strafefire</td>\n",
       "      <td>http://yousuckattrading.com/2009/01/how-to-cre...</td>\n",
       "      <td>/r/StockMarket/comments/7tpzv/how_to_create_an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    subreddit  created_utc  \\\n",
       "0  6qxh3  StockMarket   1215605912   \n",
       "1  6qxh8  StockMarket   1215605967   \n",
       "2  7tpzv  StockMarket   1233351595   \n",
       "\n",
       "                                               title selftext  score  \\\n",
       "0  Forex Trading Styles: Fundamental analysis - T...               1   \n",
       "1  How to invest your first 100$ in the stock market               3   \n",
       "2  How to create and test a trading strategy, Par...               1   \n",
       "\n",
       "   num_comments       author  \\\n",
       "0             1  marketstock   \n",
       "1             1  marketstock   \n",
       "2             0   strafefire   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://www.marketstock.net/2008/07/forex-tradi...   \n",
       "1  http://www.marketstock.net/2008/06/how-to-inve...   \n",
       "2  http://yousuckattrading.com/2009/01/how-to-cre...   \n",
       "\n",
       "                                           permalink  \n",
       "0  /r/StockMarket/comments/6qxh3/forex_trading_st...  \n",
       "1  /r/StockMarket/comments/6qxh8/how_to_invest_yo...  \n",
       "2  /r/StockMarket/comments/7tpzv/how_to_create_an...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Resolve project root whether this notebook is opened from /notebooks or repo root\n",
    "CWD = Path.cwd()\n",
    "ROOT = CWD if (CWD / \"data\").exists() else CWD.parent\n",
    "\n",
    "# Directory where the submission parquet parts were written\n",
    "SUB_DIR = ROOT / \"data\" / \"processed\" / \"submissions\"\n",
    "\n",
    "# Collect all parquet parts across included subreddits\n",
    "paths = sorted(glob(str(SUB_DIR / \"*.parquet\")))\n",
    "print(f\"Found parquet parts: {len(paths)} files\")\n",
    "\n",
    "# Load in chunks to be memory-friendly\n",
    "dfs = [pd.read_parquet(p) for p in paths]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Quick peek at raw columns\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Timestamp Normalization and Period Restriction (2022‚ÄìPresent)\n",
    "\n",
    "The `created_utc` field may appear as integers (Unix seconds) or strings.  \n",
    "We normalize it to timezone-aware UTC timestamps using a two-pass strategy:\n",
    "1) parse as Unix seconds;\n",
    "2) for failures, parse generically as datetime.\n",
    "\n",
    "We then restrict the sample to posts dated from **2022-01-01** to the most recent available date and display the retained date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retained date range:\n",
      "2022-01-01 00:01:45+00:00 ‚Üí 2024-12-31 23:58:51+00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def to_utc_ts(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Robustly convert 'created_utc' to timezone-aware UTC timestamps.\n",
    "    Tries epoch seconds first; falls back to generic parsing.\n",
    "    \"\"\"\n",
    "    s1 = pd.to_datetime(series, unit=\"s\", errors=\"coerce\", utc=True)\n",
    "    s2 = pd.to_datetime(series, errors=\"coerce\", utc=True)\n",
    "    return s1.fillna(s2)\n",
    "\n",
    "# Normalize timestamps\n",
    "df[\"created_utc\"] = to_utc_ts(df[\"created_utc\"])\n",
    "df = df.dropna(subset=[\"created_utc\"])\n",
    "\n",
    "# Filter: keep 2022-01-01 and later\n",
    "DATE_MIN = pd.Timestamp(\"2022-01-01\", tz=\"UTC\")\n",
    "df = df[df[\"created_utc\"] >= DATE_MIN].copy()\n",
    "\n",
    "# Show retained date range\n",
    "print(\"Retained date range:\")\n",
    "print(df[\"created_utc\"].min(), \"‚Üí\", df[\"created_utc\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Duplicate Removal\n",
    "\n",
    "We remove duplicate posts to ensure each Reddit submission is represented once.  \n",
    "Deduplication is performed on the unique submission identifier `id`.  \n",
    "We report the number of rows removed and the number remaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates removed: 5\n",
      "Rows remaining:     854855\n"
     ]
    }
   ],
   "source": [
    "before = len(df)\n",
    "df = df.drop_duplicates(subset=[\"id\"], keep=\"last\")\n",
    "after = len(df)\n",
    "\n",
    "print(f\"Duplicates removed: {before - after}\")\n",
    "print(f\"Rows remaining:     {after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Column Selection and Content Cleaning\n",
    "\n",
    "For downstream analysis we retain only the following variables:\n",
    "\n",
    "- `subreddit`: the community of origin (categorical context);\n",
    "- `timecreated`: a *date-only* version of the timestamp (no intra-day time);\n",
    "- `title`: the textual signal to be used in NLP.\n",
    "\n",
    "We remove posts whose title is exactly **‚Äú[deleted by user]‚Äù** (case-insensitive), as these do not contain analyzable content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>timecreated</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StockMarket</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Happy 2022 year!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StockMarket</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>I did the meme! üëÅüëÑüëÅ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StockMarket</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Mercedes Benz EQS 2022 ( Electric Car ) Hits t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StockMarket</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>WALL STREET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StockMarket</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>2022 investing tips and goals.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit timecreated                                              title\n",
       "0  StockMarket  2022-01-01                                   Happy 2022 year!\n",
       "1  StockMarket  2022-01-01                                I did the meme! üëÅüëÑüëÅ\n",
       "2  StockMarket  2022-01-01  Mercedes Benz EQS 2022 ( Electric Car ) Hits t...\n",
       "3  StockMarket  2022-01-01                                        WALL STREET\n",
       "4  StockMarket  2022-01-01                     2022 investing tips and goals."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure title is a string and not missing\n",
    "df[\"title\"] = df[\"title\"].fillna(\"\").astype(str)\n",
    "\n",
    "# Remove rows where the title is exactly \"[deleted by user]\" (case-insensitive, trimmed)\n",
    "mask_deleted_by_user = df[\"title\"].str.strip().str.lower().eq(\"[deleted by user]\")\n",
    "df = df[~mask_deleted_by_user].copy()\n",
    "\n",
    "# Create a date-only column (no time-of-day)\n",
    "df[\"timecreated\"] = df[\"created_utc\"].dt.date\n",
    "\n",
    "# Keep only requested columns\n",
    "df_final = df[[\"subreddit\", \"timecreated\", \"title\"]].reset_index(drop=True)\n",
    "\n",
    "# Sanity peek\n",
    "df_final.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary Checks \n",
    "\n",
    "We provide basic descriptive checks to verify the final structure and content distribution.  \n",
    "These checks are optional but facilitate quick validation of preprocessing outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique subreddits: 5\n",
      "subreddit\n",
      "wallstreetbets    538022\n",
      "stocks            105956\n",
      "investing         102895\n",
      "StockMarket        64248\n",
      "finance            34469\n",
      "Name: count, dtype: Int64\n",
      "Date range: 2022-01-01 ‚Üí 2024-12-31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>timecreated</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25447</th>\n",
       "      <td>StockMarket</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>Cenntro stock ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403010</th>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>Bullish on getting fucked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211869</th>\n",
       "      <td>stocks</td>\n",
       "      <td>2022-03-13</td>\n",
       "      <td>What to do about SEV?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211050</th>\n",
       "      <td>stocks</td>\n",
       "      <td>2022-03-08</td>\n",
       "      <td>Why are CNN Futures so different?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258687</th>\n",
       "      <td>stocks</td>\n",
       "      <td>2023-07-23</td>\n",
       "      <td>Check How Optimized Your Portfolio Is?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             subreddit timecreated                                   title\n",
       "25447      StockMarket  2022-12-31                         Cenntro stock ?\n",
       "403010  wallstreetbets  2022-06-15               Bullish on getting fucked\n",
       "211869          stocks  2022-03-13                   What to do about SEV?\n",
       "211050          stocks  2022-03-08       Why are CNN Futures so different?\n",
       "258687          stocks  2023-07-23  Check How Optimized Your Portfolio Is?"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Unique subreddits:\", df_final[\"subreddit\"].nunique())\n",
    "print(df_final[\"subreddit\"].value_counts().head(10))\n",
    "print(\"Date range:\", df_final[\"timecreated\"].min(), \"‚Üí\", df_final[\"timecreated\"].max())\n",
    "df_final.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final cleaned dataset saved here:\n",
      "/Users/lucasvercauteren/Desktop/passion-project/return-supervised-nlp-finance/data/processed/clean/reddit_posts_minimal_2022plus.parquet\n",
      "Number of rows: 845590\n"
     ]
    }
   ],
   "source": [
    "# SAVE FINAL CLEAN DATASET (2022 -> most recent)\n",
    "from pathlib import Path\n",
    "\n",
    "# create dedicated folder for cleaned datasets\n",
    "CLEAN_DIR = ROOT / \"data\" / \"processed\" / \"clean\"\n",
    "CLEAN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# final filename (very clear + version stable)\n",
    "OUT_PATH = CLEAN_DIR / \"reddit_posts_minimal_2022plus.parquet\"\n",
    "\n",
    "df.to_parquet(OUT_PATH, index=False)\n",
    "\n",
    "print(\"‚úÖ Final cleaned dataset saved here:\")\n",
    "print(str(OUT_PATH))\n",
    "print(\"Number of rows:\", len(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
